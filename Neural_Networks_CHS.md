# 神经网络 

标签（空格分隔）： ML

---

## 神经网络

此文档的目的是回顾神经网络，讨论训练规则，以及使用一个例子来阐述后向传播。

[感知机和感知机规则](/#感知机和感知机规则)

[梯度下降/Delta规则](/#梯度下降/Delta规则)

[神经网络](/#神经网络)

[后向传播](/#后向传播)

在第三课中，Michael讲解了神经网络。这份笔记意在为多种训练规则填充更多的细节。

在课上已经说过，神经网络是一个被设计为模仿生物的神经元网络的学习结构。最基础的（人工的）神经网络只由一个神经元组成，也就是感知机。我们将从感知机如何工作说起，并讨论最基础的训练规则：感知机规则。

### 感知机和感知机规则

![](http://ww3.sinaimg.cn/large/006y8lVagw1fapdl7vni2j30sa0o00u4.jpg)

在上图中，$\theta$是触发阈值，$w_i$是权重，$x_i$是输入，$y_i$是（离散的）输出。一般来说，神经网络是可以有连续输出的，但是在本文档中我们只讨论离散输出。感知机根据如下的数学公式计算输出：$$\hat y = \chi (\sum^n _{i=1} w_i x_i - \theta) = \chi (w\cdot x - \theta).$$

其中$\chi(a)$为特征函数，定义为$$\chi (a) = 1 \text{ if } a \ge 0 \text{  and } \chi (a) = 0 \text{ if } a \le 0.$$

我们可以把感知机看作是一个$n$维的超平面，它与向量$w = (w_1, w_2, ..., w_n)$垂直。感知机把平面一侧的点归类于正类，把另一面的点归类为负类。下图就是一个$w=(5, -3)$和$\theta=0$的超平面。

![](http://ww1.sinaimg.cn/large/006y8lVagw1fapei0tqasj30ng0mq0td.jpg)

为了能让感知机成为一个可以学习的模型，我们需要能用新的数据来训练它。为了说明我们如何做到这一点，考虑一个有两个输入$x_1$和$x_2$的感知机，权重和触发阈值如上。假设我们得到了一个以元组$(x_1, x_2, y)$的形式表达的训练点$(2,5,1)$。

可以看出，现在的感知机在这个训练点上的表现并不好。感知机输出的是$\hat y = 0$，但是训练点的值是$y=1$。我们应该怎么改变感知机来让它更好的进行预测呢？答案是我们最好能改变一下它的权重（毕竟我们不能改变数据）。从几何学的角度来看，我们可以考虑转动这个超平面来使训练数据处于正确的一侧。

![](http://ww1.sinaimg.cn/large/006y8lVagw1fapi5ypmc4j30mm0lumxt.jpg)

我们应该怎么进行这个转动呢？这个问题的答案中的方法我们也可以重复的在相似的情形下使用。

一个可能的答案是我们可以通过把$x$和$w$加在一起得到一个新的权重向量$w'$。从几何学的角度来看，我们能得到下图中的新的权重向量和新的超平面、分类区域：

![](http://ww2.sinaimg.cn/large/006y8lVagw1fapi6cnab4j30mw0mgt9l.jpg)

完美！这次我们的权重向量能让感知机正确的把$x=(2, 5)$这个点分类了。因此，主要的问题是，我们能不能推导出一个更一般化的规则来涵盖上面的步骤？一种可能的规则是$$w' = w+x.$$

然而虽然这是一个很好的猜测（因为它确实涵盖了上面的步骤），这个规则在感知机把一个负类错误的分类成正类的情况下却失效了。为什么？因为在这种分类错误的情形下，我们实际上想要把超平面*转离*这个数据点来使它处在边界的负类（你花点时间画一些例子来让你自己相信这一点肯定值得）。这个规则也没有涵盖感知机正确分类了数据的情况，这时我们根本不需要更新权重。为了涵盖两种分类错误的情形和分类正确的情形，我们需要仔细的观察了。如果$y$表示目标输出，$\hat y$表示感知机的输出，那么：

- 当我们正确分类数据点时，$y-\hat y=0$
- 当我们错误的把正类数据点($+1$)分类为负类($-1$)时，$y - \hat y = 1$
- 当我们错误的把负类数据点($-1$)分类为正类($+1$)时，$y - \hat y = -1$

有了这些观察，我们提出规则$$w' = w + (y-\hat y)x$$作为更新权重向量的方法。这也（几乎）就是感知机的训练规则了！在实践中，我们还会想要控制超平面能转动多少。这是通过在上面的方程中引入一个乘数 “学习率”$\eta$来完成的的。最终的结果是：

$$w' = w + \eta(y-\hat y)x$$

按照向量元素来写，并把最后一项记为$\Delta w$时，我们就得到了和课程中的形式相似的：

$$w' _i = w_i + \Delta w_i\\
= w_i + \eta(y - \hat y) x_i$$

我们知道，能够证明只要$\eta$足够小且训练数据线性可分的话，上面的更新权重的过程能在有限次的重复后收敛，并且能正确的分类所有的训练数据。


### 梯度下降/Delta规则

上面概括的感知机规则在数据线性可分的时候表现的很好，但是数据线性不可分的时候却将无法收敛。对于更复杂的数据，我们需要更好的训练规则。一个思路是创造一个衡量当前有多少误差的函数，然后通过调整权重来使这个错误最小化。我们第一次能想到的误差函数可能是这样的：$$E(w)=\sum_{d\in D}|y_d - \hat y_d|,$$其中$D$是所有训练样本的集合。这个还蛮说得通的；只是简单的把所有误差的大小加起来。然而这个方程有个问题。为了得到$E(w)$的最小值，我们需要使用微分，但是绝对值函数$|\cdot|$和阈值化的感知机输出$\hat y$都是不可微的。为了解决这个问题，人们通常考虑使用一个不使用阈值的感知机$$\hat y = w \cdot x，$$并把绝对值函数$|\cdot|$用一个二次项代替。得到的误差方程为：$$E(w)={1\over 2} \sum _{d\in D} (y_d - w \cdot x_d)^w$$
额外的$1/2$只是为了让微分表达式变得更简单，并不是必要的。这里的思路是如果我们能找到一个权重让不使用阈值的感知机——也称为*线性单元*——的输出$w\cdot x_d$接近于正确的值$y_d$，那么使用阈值的感知机也能得到一个不错的输出。

要更新权重，我们使用课程中介绍的梯度下降方法。课程中也同样给出了误差函数的梯度的推导。结果是$$\Delta w_i = \eta \sum_{d\in D} (y_d - w \cdot x_d)x_{id}.$$

请注意对于单个的数据点，梯度下降的训练规则的形式为$$\Delta w_i = \eta (y - w \cdot x)x_i，$$这和感知机的训练规则非常像！

### 神经网络

很好，现在我们有了针对线性单元的先进而灵活的训练规则，我们可以开始把一些单元链接起来组成网络了。用这个新创建的网络，我们就可以对更加复杂的函数建模了，对吗？

好吧，不完全是。实际上我们还有一个大问题。

要使用上面的梯度下降，我们必须使用一个线性单元。这个单元只是一个线性函数，当你把很多这种单元链接起来时，你就得到了一个线性函数的线性结合，它其实也是...线性的。所以我们就有了一个难题：我们想要带阈值感知机的非线性性，又想要梯度下降这个稳健的训练规则。

解决方案是如下的sigmoid函数:$$\sigma(x) =  {{1}\over{1 + e ^{-x}}}$$

Sigmoid函数的图像如图：

![](http://ww2.sinaimg.cn/large/006y8lVagw1fapi6pbdy0j30pc0ie3z0.jpg)

注意，sigmoid函数非常像一个平滑处理过的阈值函数。它也确实是平滑的。此外，sigmoid还有一个很棒的微分特性$${{d\sigma(x)}\over{dx}} = \sigma(x)\cdot (1 - \sigma(x)).$$

所以我们能让按照如下规则工作的感知机（sigmoid单元）：$$\hat y=\sigma(w\cdot x),$$给我们这两个最好的特性：sigmoid单元是非线性的并且我们仍然能使用梯度下降。

针对sigmoid单元的梯度下降训练规则为：$$\Delta w_i=\eta \sum _{d\in D} (y_d - \sigma)\cdot \sigma \cdot (1 - \sigma)x_{id}. $$
此处使用$\sigma$作为$\sigma(w\cdot x_d)$的简写。

官与神经网络训练规则的最后的考虑是如何更新网络中所有的权重。因为所有的sigmoid单元都是链接在一起的，所有单元的输入和输出都和其他单元相关。这种把梯度下降一次性应用到整个网络的方法叫做后向传播。下一个部分使用了一个例子来阐明这个名字的由来。

#### 后向传播

在对神经网络的描绘中，Michael讨论了后向传播作为神经网络学习的一种方式。这里，我们用一个带有两个输入和一个输出的神经网络来阐述后向传播。带有节点编号的网络如图所示。

![](http://ww4.sinaimg.cn/large/006y8lVagw1fapi6zvpr5j30ui0e6my1.jpg)

在这个例子中，激励函数将由上面讨论过的sigmoid给出：$$\sigma(x)={1\over{1+e^{-x}}}$$

一开始，神经网络中所有权重都设置为随机的较小的权重。此处$w_{(x1)1}$表示输入$x_1$和节点$1$之间的权重。节点一的输入被表示为$y_1$，计算它的方程如下：

![](http://ww2.sinaimg.cn/large/006y8lVagw1fapi7aqp2rj30x80ekdh3.jpg)

在节点$1$之后，我们可以使用同样的方法计算$y_2$，也就是节点$2$的输出。可以在下图中看到：

![](http://ww4.sinaimg.cn/large/006y8lVagw1fapi7mllzpj30ws0d2q46.jpg)

最后，使用权重$w_13$和$w_23$和sigmoid函数来计算最终的输出$y$。

![](http://ww2.sinaimg.cn/large/006y8lVagw1fapi80w2qcj30w20deq42.jpg)

有了输出$y$，我们就可以计算真实的值$y_{truth}$和$y$直接的误差$\delta_3$。这是误差反向传播的开始。

![](http://ww2.sinaimg.cn/large/006y8lVagw1fapi8ce0uwj30vk0dkjsk.jpg)

计算出了$\delta_3$之后，我们就可以使用权重$w_{13}$来计算节点$1$的误差$\delta_1$。

![](http://ww4.sinaimg.cn/large/006y8lVagw1fapi8jqig3j30tq0dit9w.jpg)

相似的，可以计算出节点$2$的误差$\delta_2$。

![](http://ww1.sinaimg.cn/large/006y8lVagw1fapi8s75dbj30u20dcjsn.jpg)

最终，我们可以使用输入和后向传播回来的误差一起来计算更新后的 权重$w'_{(x1)1}$和$w'_{(x2)1}$。这一步的依据是sigmoid函数的梯度下降方程。在如下的方程中，$\eta$参数用于控制学习率。在下面的方程中，$e = w_{(x1)1} \cdot x_1 + w_{(x2)1} \cdot x_2$。

![](http://ww2.sinaimg.cn/large/006y8lVagw1fapi93ww3gj30y40eygnk.jpg)

相似的，我们可以计算更新后的权重$w'_{(x1)2}$和$w'_{(x2)2}$。和上一个图中相似，下面的方程中，$e = w_{(x1)2} \cdot x_1 + w_{(x2)2} \cdot x_2$。

![](http://ww3.sinaimg.cn/large/006y8lVagw1fapi9e0bzqj30ya0hiq4w.jpg)

最后，我们可以通过同样的过程来更新权重$w'_{12}$和$w'_{22}$。

![](http://ww1.sinaimg.cn/large/006y8lVagw1fapi9n4lqej30yq0fqmyv.jpg)

如果想看一个更加深入的带有隐藏层的例子（和这个例子中的激励），请参考这个[链接](https://www.google.com/url?q=http%3A%2F%2Fgalaxy.agh.edu.pl%2F~vlsi%2FAI%2Fbackp_t_en%2Fbackprop.html&sa=D&sntz=1&usg=AFQjCNEpAQZhCy1X3hCPk9enPSi8RsAxtQ)。